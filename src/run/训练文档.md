## 1 polyvoreå‹ç¼©åŒ…è§£å‹åä»¥polyvoreä¸ºæ•´ä½“æ–‡ä»¶å¤¹åå­—æ”¾åˆ°outfit-transformer/src/data/datasetsä¸­

## 2 è®­ç»ƒå‘½ä»¤è¡Œ

## ğŸ‹ï¸ Training & Evaluation

### Step 1: Precompute CILP Embeddings

Before proceeding with training, make sure to precompute the CLIP embeddings, as all subsequent steps rely on these precomputed features.

```bash
python -m src.run.1_generate_clip_embeddings
```

### Step 2: Compatibility Prediction

Train the model for the Compatibility Prediction (CP) task.

#### ğŸ”¥ Train

```bash
python -m src.run.2_train_compatibility \
--wandb_key $YOUR/WANDB/API/KEY
```

#### ğŸ¯ Test

```bash
python -m src.run.2_test_compatibility \
--checkpoint $PATH/TO/LOAD/MODEL/.PT/FILE
```
```bash
python -m src.run.2_test_compatibility \
--checkpoint /root/autodl-tmp/compatibility_clip_cp_experiment_001_best_model.pth
```

### Step 3: Complementary Item Retrieval

After completing Step 1, use the best checkpoint from the Compatibility Prediction task to train for the Complementary Item Retrieval (CIR) task.

#### ğŸ”¥ Train

```bash
python -m src.run.3_train_complementary \
--wandb_key $YOUR/WANDB/API/KEY \
--checkpoint $PATH/TO/LOAD/MODEL/.PT/FILE
```

#### ğŸ¯ Test

```bash
python -m src.run.3_test_complemenatry \
--checkpoint $PATH/TO/LOAD/MODEL/.PT/FILE
```

## ğŸš€ å¿«é€Ÿè°ƒè¯•ä¸æ•°æ®é‡æ§åˆ¶

### å¿«é€Ÿè°ƒè¯•æ¨¡å¼

å¦‚æœæ•°æ®é‡å¤ªå¤§æˆ–æƒ³å¿«é€ŸéªŒè¯ä»£ç æ˜¯å¦æ­£å¸¸ï¼Œå¯ä»¥ä½¿ç”¨ `--demo` å‚æ•°ï¼š

```bash
# å…¼å®¹æ€§è®­ç»ƒï¼ˆåªè®­ç»ƒå‰å‡ ä¸ªbatchï¼‰
python -m src.run.2_train_compatibility --demo

# äº’è¡¥æ€§è®­ç»ƒï¼ˆåªè®­ç»ƒå‰å‡ ä¸ªbatchï¼‰
python -m src.run.3_train_complementary --demo
```

### å‡å°‘è®­ç»ƒæ•°æ®é‡

å¦‚æœæ•°æ®é›†å¤ªå¤§ï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼å‡å°‘è®­ç»ƒæ•°æ®é‡ï¼š

#### æ–¹æ³•1ï¼šä½¿ç”¨æ•°æ®é‡é™åˆ¶å‚æ•°ï¼ˆæ¨èï¼‰

```bash
# åªä½¿ç”¨å‰2000æ¡æ•°æ®è®­ç»ƒå…¼å®¹æ€§æ¨¡å‹
python -m src.run.2_train_compatibility --data_limit 40000

# åªä½¿ç”¨å‰1000æ¡æ•°æ®è®­ç»ƒäº’è¡¥æ€§æ¨¡å‹
python -m src.run.3_train_complementary --data_limit 40000
```

#### æ–¹æ³•2ï¼šè°ƒæ•´æ‰¹æ¬¡å¤§å°

```bash
# å‡å°‘æ¯GPUçš„æ‰¹æ¬¡å¤§å°
python -m src.run.2_train_compatibility --batch_sz_per_gpu 128

# å‡å°‘å·¥ä½œè¿›ç¨‹æ•°
python -m src.run.2_train_compatibility --n_workers_per_gpu 2
```

#### æ–¹æ³•3ï¼šå‡å°‘è®­ç»ƒè½®æ•°

```bash
# åªè®­ç»ƒ50ä¸ªepoch
python -m src.run.2_train_compatibility --n_epochs 50
```

### å¸¸ç”¨å‚æ•°è¯´æ˜

| å‚æ•°                    | è¯´æ˜            | é»˜è®¤å€¼ | å»ºè®®å€¼ï¼ˆå°æ•°æ®é‡ï¼‰ |
| ----------------------- | --------------- | ------ | ------------------ |
| `--data_limit`        | é™åˆ¶è®­ç»ƒæ•°æ®é‡  | æ— é™åˆ¶ | 1000-5000          |
| `--batch_sz_per_gpu`  | æ¯GPUæ‰¹æ¬¡å¤§å°   | 512    | 128-256            |
| `--n_workers_per_gpu` | æ¯GPUå·¥ä½œè¿›ç¨‹æ•° | 4      | 2                  |
| `--n_epochs`          | è®­ç»ƒè½®æ•°        | 200    | 50-100             |
| `--demo`              | å¿«é€Ÿè°ƒè¯•æ¨¡å¼    | False  | Trueï¼ˆè°ƒè¯•æ—¶ï¼‰     |

### æ•°æ®é‡å»ºè®®

- **è°ƒè¯•é˜¶æ®µ**ï¼šä½¿ç”¨ `--demo` æˆ– `--data_limit 500`
- **å¿«é€Ÿå®éªŒ**ï¼šä½¿ç”¨ `--data_limit 2000-5000`
- **æ­£å¼è®­ç»ƒ**ï¼šä½¿ç”¨å…¨é‡æ•°æ®æˆ– `--data_limit 10000+`

## Demo

Follow the steps below to run the demo:

#### Build Database

```
python -m src.demo.1_generate_rec_embeddings \
--checkpoint $PATH/OF/MODEL/.PT/FILE
```

#### Build Faiss Index.

```
python -m src.demo.2_build_index
```

#### Run Demo

```
python -m src.demo.3_run \
--checkpoint $PATH/OF/MODEL/.PT/FILE
```
