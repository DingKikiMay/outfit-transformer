## 1 polyvore压缩包解压后以polyvore为整体文件夹名字放到outfit-transformer/src/data/datasets中

## 2 训练命令行

## 🏋️ Training & Evaluation

### Step 1: Precompute CILP Embeddings

Before proceeding with training, make sure to precompute the CLIP embeddings, as all subsequent steps rely on these precomputed features.

```bash
python -m src.run.1_generate_clip_embeddings
```

### Step 2: Compatibility Prediction

Train the model for the Compatibility Prediction (CP) task.

#### 🔥 Train

```bash
python -m src.run.2_train_compatibility \
--wandb_key $YOUR/WANDB/API/KEY
```

#### 🎯 Test

```bash
python -m src.run.2_test_compatibility \
--checkpoint $PATH/TO/LOAD/MODEL/.PT/FILE
```
```bash
python -m src.run.2_test_compatibility \
--checkpoint /root/autodl-tmp/compatibility_clip_cp_experiment_001_best_model.pth
```

### Step 3: Complementary Item Retrieval

After completing Step 1, use the best checkpoint from the Compatibility Prediction task to train for the Complementary Item Retrieval (CIR) task.

#### 🔥 Train

```bash
python -m src.run.3_train_complementary \
--wandb_key $YOUR/WANDB/API/KEY \
--checkpoint $PATH/TO/LOAD/MODEL/.PT/FILE
```

#### 🎯 Test

```bash
python -m src.run.3_test_complemenatry \
--checkpoint $PATH/TO/LOAD/MODEL/.PT/FILE
```

## 🚀 快速调试与数据量控制

### 快速调试模式

如果数据量太大或想快速验证代码是否正常，可以使用 `--demo` 参数：

```bash
# 兼容性训练（只训练前几个batch）
python -m src.run.2_train_compatibility --demo

# 互补性训练（只训练前几个batch）
python -m src.run.3_train_complementary --demo
```

### 减少训练数据量

如果数据集太大，可以通过以下方式减少训练数据量：

#### 方法1：使用数据量限制参数（推荐）

```bash
# 只使用前2000条数据训练兼容性模型
python -m src.run.2_train_compatibility --data_limit 40000

# 只使用前1000条数据训练互补性模型
python -m src.run.3_train_complementary --data_limit 40000
```

#### 方法2：调整批次大小

```bash
# 减少每GPU的批次大小
python -m src.run.2_train_compatibility --batch_sz_per_gpu 128

# 减少工作进程数
python -m src.run.2_train_compatibility --n_workers_per_gpu 2
```

#### 方法3：减少训练轮数

```bash
# 只训练50个epoch
python -m src.run.2_train_compatibility --n_epochs 50
```

### 常用参数说明

| 参数                    | 说明            | 默认值 | 建议值（小数据量） |
| ----------------------- | --------------- | ------ | ------------------ |
| `--data_limit`        | 限制训练数据量  | 无限制 | 1000-5000          |
| `--batch_sz_per_gpu`  | 每GPU批次大小   | 512    | 128-256            |
| `--n_workers_per_gpu` | 每GPU工作进程数 | 4      | 2                  |
| `--n_epochs`          | 训练轮数        | 200    | 50-100             |
| `--demo`              | 快速调试模式    | False  | True（调试时）     |

### 数据量建议

- **调试阶段**：使用 `--demo` 或 `--data_limit 500`
- **快速实验**：使用 `--data_limit 2000-5000`
- **正式训练**：使用全量数据或 `--data_limit 10000+`

## Demo

Follow the steps below to run the demo:

#### Build Database

```
python -m src.demo.1_generate_rec_embeddings \
--checkpoint $PATH/OF/MODEL/.PT/FILE
```

#### Build Faiss Index.

```
python -m src.demo.2_build_index
```

#### Run Demo

```
python -m src.demo.3_run \
--checkpoint $PATH/OF/MODEL/.PT/FILE
```
