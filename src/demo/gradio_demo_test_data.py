import os
# è®¾ç½®ç¯å¢ƒå˜é‡è§£å†³OpenMPå†²çª
os.environ['KMP_DUPLICATE_LIB_OK'] = 'TRUE'

import gradio as gr
from dataclasses import dataclass
from typing import List, Optional, Literal
from PIL import Image
import torch
import random
import json
import base64
import io
import pickle
from argparse import ArgumentParser
import pathlib
import numpy as np

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = pathlib.Path(__file__).parent.parent.parent
import sys
sys.path.insert(0, str(project_root))

# ä½¿ç”¨ç»å¯¹å¯¼å…¥
from src.demo.vectorstore import FAISSVectorStore
from src.models.load import load_model
from src.data import datatypes
from src.data.datasets import polyvore_utils as polyvore

SRC_DIR = pathlib.Path(__file__).parent.parent.parent.absolute()
LOGS_DIR = SRC_DIR / 'logs'
os.environ["TOKENIZERS_PARALLELISM"] = "false"
os.makedirs(LOGS_DIR, exist_ok=True)

# è®¾ç½®æ¯é¡µæ˜¾ç¤º12ä¸ªå•†å“ï¼Œæ¯æ¬¡æœç´¢è¿”å›8ä¸ªç»“æœ
ITEM_PER_PAGE = 12
ITEM_PER_SEARCH = 8

# å…¨å±€çŠ¶æ€å˜é‡ï¼šç”¨æˆ·é€‰æ‹©çš„å•†å“å’Œå€™é€‰å•†å“
state_my_items = []
state_candidate_items = []


def parse_args():
    parser = ArgumentParser()
    parser.add_argument('--model_type', type=str, choices=['original', 'clip'],
                        default='clip')
    parser.add_argument('--test_data_dir', type=str, 
                        default='./src/test/test_data')
    parser.add_argument('--checkpoint', type=str, 
                        default='./best_path/complementary_clip_cir_experiment_001_best_model.pth')
    parser.add_argument('--port', type=int, default=8080, help="æœåŠ¡å™¨ç«¯å£")
    parser.add_argument('--host', type=str, default="0.0.0.0", help="æœåŠ¡å™¨ä¸»æœº")
    parser.add_argument('--share', action='store_true', help="æ˜¯å¦åˆ†äº«é“¾æ¥")
    
    return parser.parse_args()


def load_test_data(test_data_dir):
    """åŠ è½½test_dataä¸­çš„å•†å“æ•°æ®"""
    result_file = os.path.join(test_data_dir, 'test.json')
    images_dir = os.path.join(test_data_dir, 'images')
    
    with open(result_file, 'r', encoding='utf-8') as f:
        products = json.load(f)
    
    # è½¬æ¢ä¸ºFashionItemæ ¼å¼
    fashion_items = []
    for i, product in enumerate(products):
        try:
            # è·å–item_idï¼Œå¦‚æœJSONä¸­æœ‰åˆ™ä½¿ç”¨ï¼Œå¦åˆ™ä½¿ç”¨ç´¢å¼•+2ï¼ˆä»2å¼€å§‹ï¼‰
            item_id = str(product.get('item_id', i + 2))
            
            # æ„å»ºå›¾ç‰‡è·¯å¾„ï¼Œä½¿ç”¨item_id
            image_path = os.path.join(images_dir, f"{item_id}.jpg")
            if os.path.exists(image_path):
                image = Image.open(image_path).convert('RGB')
                
                # åˆ›å»ºFashionItem
                scene_value = product.get('åœºæ™¯', 'é€šç”¨')
                # ç¡®ä¿sceneæ˜¯åˆ—è¡¨ç±»å‹
                if isinstance(scene_value, str):
                    scene_list = [scene_value] if scene_value else ['é€šç”¨']
                else:
                    scene_list = scene_value if scene_value else ['é€šç”¨']
                
                fashion_item = datatypes.FashionItem(
                    item_id=int(item_id) if item_id.isdigit() else None,
                    category=product.get('ä¸»ç±»åˆ«', 'æœªçŸ¥'),
                    scene=scene_list,
                    image=image,
                    description=product.get('åç§°', ''),
                    metadata={
                        'item_id': item_id,
                        'semantic_category': product.get('ä¸»ç±»åˆ«', 'æœªçŸ¥'),
                        'scene': product.get('åœºæ™¯', 'é€šç”¨'),
                        'url_name': product.get('åç§°', ''),
                        'title': product.get('åç§°', ''),
                        'price': product.get('å‘å”®ä»·æ ¼'),
                        'brand': product.get('å“ç‰Œ', ''),
                        'sub_category': product.get('å­ç±»åˆ«', ''),
                        'style': product.get('é£æ ¼', ''),
                        'pattern': product.get('å›¾æ¡ˆ', ''),
                        'season': product.get('é€‚ç”¨å­£èŠ‚', ''),
                        'fit': product.get('ç‰ˆå‹', '')
                    },
                    embedding=None
                )
                fashion_items.append(fashion_item)
        except Exception as e:
            print(f"åŠ è½½å•†å“ {i} å¤±è´¥: {e}")
            continue
    
    print(f"æˆåŠŸåŠ è½½ {len(fashion_items)} ä»¶å•†å“")
    return fashion_items


def run(args):
    """è¿è¡ŒGradioæ¼”ç¤º"""
    
    # åŠ è½½test_data
    test_items = load_test_data(args.test_data_dir)
    
    # æŒ‰ç±»åˆ«åˆ†ç»„
    categories = list(set([item.category for item in test_items]))
    
    # å¤„ç†åœºæ™¯åˆ—è¡¨ï¼Œæå–æ‰€æœ‰å”¯ä¸€çš„åœºæ™¯å€¼
    all_scenes = []
    for item in test_items:
        if item.scene:
            if isinstance(item.scene, list):
                all_scenes.extend(item.scene)
            else:
                all_scenes.append(item.scene)
    scenes = list(set(all_scenes))
    
    num_pages = len(test_items) // ITEM_PER_PAGE
    
    # æ ¹æ®é¡µç è¿”å›å¯¹åº”é¡µçš„å•†å“åˆ—è¡¨
    def get_items(page):
        start_idx = page * ITEM_PER_PAGE
        end_idx = min((page + 1) * ITEM_PER_PAGE, len(test_items))
        return test_items[start_idx:end_idx]

    # åŠ è½½æ¨¡å‹
    model = load_model(
        model_type=args.model_type, checkpoint=args.checkpoint
    )
    model.eval()
    
    # åŠ è½½é¢„è®¡ç®—çš„embeddingå­—å…¸
    embedding_dict = None
    embedding_dir = os.path.join(args.test_data_dir, 'precomputed_rec_embeddings')
    embedding_dict_path = os.path.join(embedding_dir, 'test_data_embedding_dict.pkl')
    
    if os.path.exists(embedding_dict_path):
        print("åŠ è½½é¢„è®¡ç®—çš„embeddingå­—å…¸...")
        with open(embedding_dict_path, 'rb') as f:
            embedding_dict = pickle.load(f)
        print(f"æˆåŠŸåŠ è½½ {len(embedding_dict)} ä¸ªé¢„è®¡ç®—embedding")
    else:
        print("è­¦å‘Šï¼šæœªæ‰¾åˆ°é¢„è®¡ç®—çš„embeddingï¼Œå°†å®æ—¶è®¡ç®—")
    
    # åŠ è½½FAISSç´¢å¼•
    indexer = None
    try:
        indexer = FAISSVectorStore(
            index_name='test_data_rec_index',
            d_embed=512,  # æ ¹æ®æ¨¡å‹è¾“å‡ºç»´åº¦è°ƒæ•´
            faiss_type='IndexFlatIP',
            base_dir=embedding_dir,
        )
        print("æˆåŠŸåŠ è½½FAISSç´¢å¼•")
    except Exception as e:
        print(f"è­¦å‘Šï¼šåŠ è½½FAISSç´¢å¼•å¤±è´¥: {e}")
        print("å°†ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦è¿›è¡Œæœç´¢")
    
    '''-----------------------------Webç•Œé¢æ„å»º-----------------------------'''
    # åˆ›å»ºGradio Webç•Œé¢
    with gr.Blocks(title="äº’è¡¥å•å“æ¨èç³»ç»Ÿ", theme=gr.themes.Soft()) as demo:
        
        with gr.Row(equal_height=True):
            gr.Markdown(
                "# ğŸ¨ äº’è¡¥å•å“æ¨èç³»ç»Ÿ"
            )
        
        with gr.Row(equal_height=True):
            gr.Markdown(
                "## ğŸ“‹ ä½¿ç”¨è¯´æ˜"
            )
        
        with gr.Row(equal_height=True):
            gr.Markdown(
                """
                1. **é€‰æ‹©å•†å“**ï¼šä»ä¸‹æ–¹ç´ æåº“ä¸­é€‰æ‹©ä¸€ä»¶ä¸Šè£…æˆ–ä¸‹è£…
                2. **è®¾ç½®ç›®æ ‡**ï¼šè¾“å…¥ç›®æ ‡å•å“çš„åœºæ™¯å’Œæè¿°ï¼ˆå¯é€‰ï¼‰
                3. **è·å–æ¨è**ï¼šç‚¹å‡»æœç´¢æŒ‰é’®ï¼Œç³»ç»Ÿä¼šæ¨èæœ€ä½³çš„äº’è¡¥å•å“
                """
            )
        
        # å•†å“åº“é€‰æ‹©åŒºåŸŸ
        with gr.Row(equal_height=True):
            gr.Markdown(
                "## ğŸ›ï¸ ç´ æåº“"
            )
        
        with gr.Row(equal_height=True):
            with gr.Column(scale=2, variant='compact'):
                # ç­›é€‰é€‰é¡¹
                with gr.Row(equal_height=True):
                    category_filter = gr.Dropdown(
                        label="æŒ‰ç±»åˆ«ç­›é€‰",
                        choices=["å…¨éƒ¨"] + categories, value="å…¨éƒ¨",
                    )
                with gr.Row(equal_height=True):
                    scene_filter = gr.Dropdown(
                        label="æŒ‰åœºæ™¯ç­›é€‰",
                        choices=["å…¨éƒ¨"] + scenes, value="å…¨éƒ¨",
                    )
                with gr.Row(equal_height=True):
                    polyvore_page = gr.Dropdown(
                        label="é¡µç ",
                        choices=list(range(1, num_pages + 1)),
                        value=1
                    )
            
            with gr.Column(scale=10, variant='compact'):
                with gr.Row(equal_height=True):
                    with gr.Column(variant='compact'):
                        polyvore_gallery = gr.Gallery(
                            allow_preview=True,
                            show_label=True,
                            columns=6, 
                            rows=3,
                            type="pil",
                            object_fit='contain',
                            height=300,
                            label="ç´ æåº“ - ç‚¹å‡»é€‰æ‹©å•†å“"
                        )
        
        # æ¨èåŒºåŸŸ
        with gr.Row(equal_height=True):
            gr.Markdown(
                "## ğŸ¯ äº’è¡¥å•å“æ¨è"
            )
        
        with gr.Row(equal_height=True):
            with gr.Column(scale=1, variant='compact'):
                # å½“å‰é€‰æ‹©çš„å•†å“æ˜¾ç¤º
                with gr.Row(equal_height=True):
                    gr.Markdown(
                        "### å½“å‰é€‰æ‹©çš„å•†å“"
                    )
                with gr.Row(equal_height=True):
                    selected_item_display = gr.Gallery(
                        allow_preview=True,
                        show_label=True,
                        columns=1,
                        rows=1,
                        type="pil",
                        object_fit='contain',
                        height=150,
                        label="å·²é€‰æ‹©çš„å•†å“"
                    )
                
                # æ¨èå‚æ•°è®¾ç½®
                with gr.Row(equal_height=True):
                    gr.Markdown(
                        "### æ¨èè®¾ç½®"
                    )
                with gr.Row(equal_height=True):
                    comp_description = gr.Textbox(
                        label="ç›®æ ‡å•å“æè¿°ï¼ˆå¯é€‰ï¼‰",
                        placeholder="å¦‚ï¼šé»‘è‰²ç‰›ä»”è£¤",
                        lines=2
                    )
                with gr.Row(equal_height=True):
                    comp_scene = gr.Dropdown(
                        label="ç›®æ ‡åœºæ™¯ï¼ˆå¯é€‰ï¼‰",
                        choices=[''] + scenes, value='',
                    )
                with gr.Row(equal_height=True):
                    btn_search_item = gr.Button(
                        "æœç´¢æ¨è", variant="primary", size="lg"
                    )
            
            with gr.Column(scale=2, variant='compact'):
                # æ¨èç»“æœ
                with gr.Row(equal_height=True):
                    gr.Markdown(
                        "### æ¨èç»“æœ"
                    )
                with gr.Row(equal_height=True):
                    searched_item_gallery = gr.Gallery(
                        allow_preview=True,
                        show_label=True,
                        columns=4, 
                        rows=2,
                        type="pil",
                        object_fit='contain',
                        height=300,
                        label="æ¨èçš„å•å“"
                    )
              
        # å…¨å±€å˜é‡ï¼šå½“å‰é€‰æ‹©çš„å•†å“
        global selected_item
        selected_item = None
        
        # Functions
        # ä»å•†å“åº“é€‰æ‹©å•†å“
        def select_item_from_library(selected: gr.SelectData):
            global selected_item, state_candidate_items
            
            if selected.index < len(state_candidate_items):
                selected_item = state_candidate_items[selected.index]
                return {
                    selected_item_display: [selected_item.image],
                }
            return {
                selected_item_display: [],
            }
        
        # ç­›é€‰å•†å“
        def filter_and_get_items(category_filter, scene_filter, page):
            global state_candidate_items
            
            # è·å–æ‰€æœ‰å•†å“ç´¢å¼•
            all_indices = list(range(len(test_items)))
            
            # æŒ‰ç±»åˆ«ç­›é€‰
            if category_filter and category_filter != "å…¨éƒ¨":
                all_indices = [i for i in all_indices if test_items[i].category == category_filter]
            
            # æŒ‰åœºæ™¯ç­›é€‰
            if scene_filter and scene_filter != "å…¨éƒ¨":
                all_indices = [i for i in all_indices if test_items[i].scene and scene_filter in test_items[i].scene]
            
            # åˆ†é¡µ
            page = page - 1
            start_idx = page * ITEM_PER_PAGE
            end_idx = min(start_idx + ITEM_PER_PAGE, len(all_indices))
            
            if start_idx >= len(all_indices):
                state_candidate_items = []
                return {
                    polyvore_gallery: []
                }
            
            page_indices = all_indices[start_idx:end_idx]
            state_candidate_items = [test_items[i] for i in page_indices]
            
            return {
                polyvore_gallery: [item.image for item in state_candidate_items],
            }
        

        

        
        # æœç´¢äº’è¡¥å•†å“å‡½æ•°ï¼šæ ¹æ®å½“å‰é€‰æ‹©çš„å•†å“å’Œç”¨æˆ·æè¿°ï¼Œæœç´¢ä¸ä¹‹äº’è¡¥çš„å•†å“
        @torch.no_grad()
        def search_item(comp_description, comp_scene):
            global selected_item
            
            if selected_item is None:
                gr.Warning("é”™è¯¯ï¼šè¯·å…ˆä»å•†å“åº“é€‰æ‹©ä¸€ä»¶å•†å“ï¼")
                return {
                    searched_item_gallery: []
                }
            
            try:
                # åˆ›å»ºç›®æ ‡å•†å“æè¿°
                target_category = "ä¸‹è£…" if selected_item.category == "ä¸Šè¡£" else "ä¸Šè¡£"
                
                # æ„å»ºç›®æ ‡å•†å“æè¿°
                target_description = ""
                if comp_description and comp_description.strip():
                    target_description = comp_description.strip()
                else:
                    # å¦‚æœæ²¡æœ‰ç”¨æˆ·è¾“å…¥æè¿°ï¼Œä½¿ç”¨é»˜è®¤æè¿°
                    target_description = f"ä¸€ä»¶{target_category}"
                
                # å¦‚æœæœ‰åœºæ™¯è¦æ±‚ï¼Œæ·»åŠ åˆ°æè¿°ä¸­
                if comp_scene and comp_scene.strip():
                    target_description += f"ï¼Œé€‚åˆ{comp_scene}åœºåˆ"
                
                print(f"ç›®æ ‡å•†å“æè¿°: {target_description}")
                
                # åˆ›å»ºç›®æ ‡å•†å“ï¼ˆè™šæ‹Ÿå•†å“ï¼Œç”¨äºæŸ¥è¯¢ï¼‰
                target_item = datatypes.FashionItem(
                    item_id=None,  # ä½¿ç”¨Noneè€Œä¸æ˜¯å­—ç¬¦ä¸²
                    image=selected_item.image,  # ä½¿ç”¨å ä½å›¾ç‰‡
                    description=target_description,
                    category=target_category,
                    scene=[comp_scene] if comp_scene else ["é€šç”¨"],
                    metadata={
                        'item_id': 'target_item',
                        'semantic_category': target_category,
                        'scene': comp_scene if comp_scene else "é€šç”¨",
                        'url_name': target_description,
                    }
                )
                
                # è®¡ç®—ç›®æ ‡å•†å“çš„embeddingï¼ˆèåˆå›¾ç‰‡å’Œæ–‡æœ¬ï¼‰
                target_embedding = model.embed_item([target_item], use_precomputed_embedding=False)
                target_embedding = target_embedding[0].cpu().numpy()
                
                # è®¡ç®—å½“å‰é€‰æ‹©å•†å“çš„embedding
                item_embedding = model.embed_item([selected_item], use_precomputed_embedding=False)
                selected_item.embedding = item_embedding[0].cpu().numpy()
                
                # åˆ›å»ºoutfitæŸ¥è¯¢
                outfit_query = datatypes.FashionComplementaryQuery(
                    outfit=[selected_item],
                    category=target_category
                )
                
                # ä½¿ç”¨ç›®æ ‡å•†å“çš„embeddingè¿›è¡Œæœç´¢ï¼ˆèåˆäº†å›¾ç‰‡å’Œæ–‡æœ¬æè¿°ï¼‰
                search_embedding = target_embedding
                
                # ä½¿ç”¨FAISSç´¢å¼•æˆ–ä½™å¼¦ç›¸ä¼¼åº¦æœç´¢
                if indexer is not None:
                    try:
                        # ä½¿ç”¨FAISSç´¢å¼•æœç´¢
                        results = indexer.search(
                            embeddings=[search_embedding],
                            k=min(ITEM_PER_SEARCH * 2, len(test_items))  # æœç´¢æ›´å¤šç»“æœç”¨äºè¿‡æ»¤
                        )
                        
                        # æ£€æŸ¥ç»“æœæ˜¯å¦ä¸ºç©º
                        if not results or len(results) == 0 or len(results[0]) == 0:
                            gr.Warning("FAISSæœç´¢æœªè¿”å›ç»“æœï¼Œä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦æœç´¢")
                            raise Exception("FAISS search returned empty results")
                        
                        # è¿‡æ»¤ç»“æœ
                        candidate_items = []
                        for score, item_id in results[0]:
                            if int(item_id) >= len(test_items):
                                continue  # è·³è¿‡æ— æ•ˆçš„item_id
                            item = test_items[int(item_id)]
                            # è¿‡æ»¤ç±»åˆ«
                            if item.category != target_category:
                                continue
                            # è¿‡æ»¤åœºæ™¯ï¼ˆå¦‚æœæŒ‡å®šï¼‰
                            if comp_scene and (not item.scene or comp_scene not in item.scene):
                                continue
                            candidate_items.append(item)
                            if len(candidate_items) >= ITEM_PER_SEARCH:
                                break
                        
                        top_items = candidate_items
                        
                    except Exception as e:
                        print(f"FAISSæœç´¢å¤±è´¥: {e}ï¼Œåˆ‡æ¢åˆ°ä½™å¼¦ç›¸ä¼¼åº¦æœç´¢")
                        # å¦‚æœFAISSå¤±è´¥ï¼Œå›é€€åˆ°ä½™å¼¦ç›¸ä¼¼åº¦æœç´¢
                        raise e
                    
                else:
                    # ä½¿ç”¨ä½™å¼¦ç›¸ä¼¼åº¦æœç´¢
                    similarities = []
                    candidate_items = []
                    
                    for item in test_items:
                        # è¿‡æ»¤ç±»åˆ«
                        if item.category != target_category:
                            continue
                        
                        # è¿‡æ»¤åœºæ™¯ï¼ˆå¦‚æœæŒ‡å®šï¼‰
                        if comp_scene and (not item.scene or comp_scene not in item.scene):
                            continue
                        
                        try:
                            # ä½¿ç”¨é¢„è®¡ç®—çš„embeddingæˆ–å®æ—¶è®¡ç®—
                            if embedding_dict and item.item_id in embedding_dict:
                                item_embedding = embedding_dict[item.item_id]
                            else:
                                item_embedding = model.embed_item([item], use_precomputed_embedding=False)
                                item_embedding = item_embedding[0].cpu().numpy()
                            
                            # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
                            similarity = np.dot(search_embedding, item_embedding) / (
                                np.linalg.norm(search_embedding) * np.linalg.norm(item_embedding)
                            )
                            
                            similarities.append(similarity)
                            candidate_items.append(item)
                        except Exception as e:
                            print(f"è®¡ç®—å•†å“ {item.item_id} çš„ç›¸ä¼¼åº¦æ—¶å‡ºé”™: {e}")
                            continue
                    
                    if not candidate_items:
                        gr.Warning("æ²¡æœ‰æ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„äº’è¡¥å•†å“ï¼")
                        return {
                            searched_item_gallery: []
                        }
                    
                    # æŒ‰ç›¸ä¼¼åº¦æ’åº
                    sorted_indices = np.argsort(similarities)[::-1]
                    top_items = [candidate_items[i] for i in sorted_indices[:ITEM_PER_SEARCH]]
                
                return {
                    searched_item_gallery: [item.image for item in top_items]
                }
                
            except Exception as e:
                gr.Warning(f"æœç´¢äº’è¡¥å•†å“å¤±è´¥: {e}")
                return {
                    searched_item_gallery: []
                }
        
        # Event Handlers
        # ç­›é€‰å’Œåˆ†é¡µ
        category_filter.change(
            filter_and_get_items,
            inputs=[category_filter, scene_filter, polyvore_page],
            outputs=[polyvore_gallery]
        )
        
        scene_filter.change(
            filter_and_get_items,
            inputs=[category_filter, scene_filter, polyvore_page],
            outputs=[polyvore_gallery]
        )
        
        polyvore_page.change(
            filter_and_get_items,
            inputs=[category_filter, scene_filter, polyvore_page],
            outputs=[polyvore_gallery]
        )
        
        # ä»å•†å“åº“é€‰æ‹©å•†å“
        polyvore_gallery.select(
            select_item_from_library,
            inputs=None,
            outputs=[selected_item_display]
        )
        
        # æœç´¢æ¨è
        btn_search_item.click(
            search_item,
            inputs=[comp_description, comp_scene],
            outputs=[searched_item_gallery]
        )
        
        # åˆå§‹åŒ–æ˜¾ç¤ºç¬¬ä¸€é¡µå•†å“
        demo.load(
            lambda: filter_and_get_items("å…¨éƒ¨", "å…¨éƒ¨", 1),
            inputs=None,
            outputs=[polyvore_gallery]
        )
    
    return demo


if __name__ == "__main__":
    args = parse_args()
    
    # å¦‚æœæ²¡æœ‰æŒ‡å®šcheckpointï¼Œä½¿ç”¨é»˜è®¤è·¯å¾„
    if args.checkpoint is None:
        args.checkpoint = "./best_path/complementary_clip_cir_experiment_001_best_model.pth"
        print(f"ä½¿ç”¨é»˜è®¤æ¨¡å‹è·¯å¾„: {args.checkpoint}")
        print("è¯·ç¡®ä¿æ¨¡å‹æ–‡ä»¶å­˜åœ¨ï¼Œæˆ–ä½¿ç”¨ --checkpoint å‚æ•°æŒ‡å®šæ­£ç¡®çš„è·¯å¾„")
    
    demo = run(args)
    demo.launch(
        server_name=args.host,
        server_port=args.port,
        share=True,  # å¼ºåˆ¶å¯ç”¨åˆ†äº«åŠŸèƒ½
        debug=True
    ) 